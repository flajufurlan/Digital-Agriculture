{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9775a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fist step is to install the mlxtend library to perform step forward feature selection \n",
    "# Random Forest classifier for feature selection and model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb152cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge mlxtend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d8aee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first steps are too make imports, load the dataset, and split it into training and testing sets.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92761fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data (csv format)\n",
    "df = pd.read_csv('winequality-white.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7056f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics\n",
    "\n",
    "FF_Description = df.describe()\n",
    "FF_Description.to_csv(\"FF_Description.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70748524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (3673, 11) (3673,)\n",
      "Testing dataset shape: (1225, 11) (1225,)\n"
     ]
    }
   ],
   "source": [
    "# In this command a train/test aplit.\n",
    "#Train Dataset: Used to fit the machine learning model.\n",
    "#Test Dataset: Used to evaluate the fit machine learning model.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.values[:,:-1],\n",
    "    df.values[:,-1:],\n",
    "    test_size=0.25,\n",
    "    random_state=42)\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "# Showing the traning/test data set shape\n",
    "print('Training dataset shape:', X_train.shape, y_train.shape)\n",
    "print('Testing dataset shape:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5579e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a classifier \n",
    "#Using random forest that is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging\n",
    "#n_estimatorsint, default=100. The number of trees in the forest.\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34ab05c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build step forward feature selection giving the subset of features that in this case are k_features=5\n",
    "# floating algorithms have an additional exclusion or inclusion step to remove features once they were included (or excluded)\n",
    "# The verbose is defined for mlxtend to report\n",
    "# The scoring to accuracy is used to score the models results that were built based on the selected features \n",
    "# mlxtend feature selector uses cross validation internally, and we set our desired folds to 5.\n",
    "sfs1 = sfs(clf,\n",
    "           k_features=5,\n",
    "           forward=True,\n",
    "           floating=False,\n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924038a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   16.4s finished\n",
      "\n",
      "[2023-02-17 12:15:24] Features: 1/5 -- score: 0.49686370460990936[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   16.2s finished\n",
      "\n",
      "[2023-02-17 12:15:40] Features: 2/5 -- score: 0.5412519231125692[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   19.5s finished\n",
      "\n",
      "[2023-02-17 12:16:00] Features: 3/5 -- score: 0.6084917236649428[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   23.9s finished\n",
      "\n",
      "[2023-02-17 12:16:24] Features: 4/5 -- score: 0.6256349515282953[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Perform SFFS\n",
    "# The score metric got comes from the subset of 5 features , using cross validation\n",
    "sfs1 = sfs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4df753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The commands are showing which features were selected for the model\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b8d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the selected features it is possible not to build a full with the traning and test sets \n",
    "# The command is building a classifier for only the subset pf the selected features\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42, max_depth=4)\n",
    "clf.fit(X_train[:, feat_cols], y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train[:, feat_cols])\n",
    "print('Training accuracy on selected features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = clf.predict(X_test[:, feat_cols])\n",
    "print('Testing accuracy on selected features: %.3f' % acc(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b8e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparision of the model above with the accuracies of another full model using all features \n",
    "# Comparision check \n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42, max_depth=4)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print('Training accuracy on all features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print('Testing accuracy on all features: %.3f' % acc(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2700740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is important to check the feature subset that will work best for the data and do the comparision with the full data set.\n",
    "# Comparing the two models the accuracy is not very high and is very similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0e29478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With six features\n",
    "# Build step forward feature selection\n",
    "# It is important to choose the right numbers of features and check because \n",
    "#it can lead to a sub-optimak numer and combination of features being decided upon \n",
    "sfs1 = sfs(clf,\n",
    "           k_features=6,\n",
    "           forward=True,\n",
    "           floating=False,\n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b24001b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   25.1s finished\n",
      "\n",
      "[2023-02-17 13:38:52] Features: 1/6 -- score: 0.495775639956255[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   18.2s finished\n",
      "\n",
      "[2023-02-17 13:39:10] Features: 2/6 -- score: 0.5407073347049991[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   18.4s finished\n",
      "\n",
      "[2023-02-17 13:39:28] Features: 3/6 -- score: 0.6063118871526813[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   22.7s finished\n",
      "\n",
      "[2023-02-17 13:39:51] Features: 4/6 -- score: 0.6269966079074681[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   16.4s finished\n",
      "\n",
      "[2023-02-17 13:40:08] Features: 5/6 -- score: 0.6351702533874586[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   13.3s finished\n",
      "\n",
      "[2023-02-17 13:40:21] Features: 6/6 -- score: 0.6438836679085803"
     ]
    }
   ],
   "source": [
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efed4cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 4, 6, 7, 10]\n"
     ]
    }
   ],
   "source": [
    "# Which features?\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b735959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy on selected features: 0.559\n",
      "Testing accuracy on selected features: 0.508\n"
     ]
    }
   ],
   "source": [
    "# Build full model with selected features\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42, max_depth=4)\n",
    "clf.fit(X_train[:, feat_cols], y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train[:, feat_cols])\n",
    "print('Training accuracy on selected features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = clf.predict(X_test[:, feat_cols])\n",
    "print('Testing accuracy on selected features: %.3f' % acc(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75acc7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the score with 6 (0.64) features a little bit higher than with 5 (0.62) features. \n",
    "# The full model built with the selected features ( training an testing accuracy) 5 and 6 are very approximate "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
